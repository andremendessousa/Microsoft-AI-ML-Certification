{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Teste inicial de Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction\n",
    "In this activity, you will apply the concepts learned in the previous lessons by implementing an ML model from scratch. This hands-on exercise will guide you through the process of building, training, and evaluating a model using your choice of ML frameworks—TensorFlow, PyTorch, or Scikit-learn. The goal is to reinforce your understanding of model implementation. By the end of this activity, you will gain practical experience in deploying a working model.\n",
    "\n",
    "By the end of this activity, you will:\n",
    "\n",
    "Build an ML model using a specified framework.\n",
    "\n",
    "Train the model on a provided dataset.\n",
    "\n",
    "Evaluate the model’s performance.\n",
    "\n",
    "Save and potentially reload the model for future use.\n",
    "\n",
    "Dataset\n",
    "You will use the CIFAR-10 dataset, a well-known dataset consisting of 60,000 32x32 color images in 10 different classes. The dataset is already split into 50,000 training images and 10,000 test images. You can download the dataset directly through the TensorFlow or PyTorch libraries, or if using Scikit-learn, you may \n",
    "download it separately\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:11<00:00, 14.8MB/s] \n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch 2000] loss: 2.205\n",
      "[Epoch 1, Batch 4000] loss: 1.852\n",
      "[Epoch 1, Batch 6000] loss: 1.643\n",
      "[Epoch 1, Batch 8000] loss: 1.561\n",
      "[Epoch 1, Batch 10000] loss: 1.499\n",
      "[Epoch 1, Batch 12000] loss: 1.436\n",
      "[Epoch 2, Batch 2000] loss: 1.403\n",
      "[Epoch 2, Batch 4000] loss: 1.350\n",
      "[Epoch 2, Batch 6000] loss: 1.353\n",
      "[Epoch 2, Batch 8000] loss: 1.340\n",
      "[Epoch 2, Batch 10000] loss: 1.313\n",
      "[Epoch 2, Batch 12000] loss: 1.293\n",
      "[Epoch 3, Batch 2000] loss: 1.237\n",
      "[Epoch 3, Batch 4000] loss: 1.241\n",
      "[Epoch 3, Batch 6000] loss: 1.211\n",
      "[Epoch 3, Batch 8000] loss: 1.225\n",
      "[Epoch 3, Batch 10000] loss: 1.204\n",
      "[Epoch 3, Batch 12000] loss: 1.214\n",
      "[Epoch 4, Batch 2000] loss: 1.114\n",
      "[Epoch 4, Batch 4000] loss: 1.143\n",
      "[Epoch 4, Batch 6000] loss: 1.143\n",
      "[Epoch 4, Batch 8000] loss: 1.147\n",
      "[Epoch 4, Batch 10000] loss: 1.126\n",
      "[Epoch 4, Batch 12000] loss: 1.144\n",
      "[Epoch 5, Batch 2000] loss: 1.049\n",
      "[Epoch 5, Batch 4000] loss: 1.057\n",
      "[Epoch 5, Batch 6000] loss: 1.067\n",
      "[Epoch 5, Batch 8000] loss: 1.077\n",
      "[Epoch 5, Batch 10000] loss: 1.079\n",
      "[Epoch 5, Batch 12000] loss: 1.080\n",
      "[Epoch 6, Batch 2000] loss: 0.978\n",
      "[Epoch 6, Batch 4000] loss: 1.009\n",
      "[Epoch 6, Batch 6000] loss: 1.020\n",
      "[Epoch 6, Batch 8000] loss: 1.001\n",
      "[Epoch 6, Batch 10000] loss: 1.025\n",
      "[Epoch 6, Batch 12000] loss: 1.025\n",
      "[Epoch 7, Batch 2000] loss: 0.930\n",
      "[Epoch 7, Batch 4000] loss: 0.965\n",
      "[Epoch 7, Batch 6000] loss: 0.944\n",
      "[Epoch 7, Batch 8000] loss: 0.981\n",
      "[Epoch 7, Batch 10000] loss: 0.976\n",
      "[Epoch 7, Batch 12000] loss: 0.973\n",
      "[Epoch 8, Batch 2000] loss: 0.891\n",
      "[Epoch 8, Batch 4000] loss: 0.915\n",
      "[Epoch 8, Batch 6000] loss: 0.914\n",
      "[Epoch 8, Batch 8000] loss: 0.938\n",
      "[Epoch 8, Batch 10000] loss: 0.950\n",
      "[Epoch 8, Batch 12000] loss: 0.950\n",
      "[Epoch 9, Batch 2000] loss: 0.847\n",
      "[Epoch 9, Batch 4000] loss: 0.873\n",
      "[Epoch 9, Batch 6000] loss: 0.887\n",
      "[Epoch 9, Batch 8000] loss: 0.889\n",
      "[Epoch 9, Batch 10000] loss: 0.908\n",
      "[Epoch 9, Batch 12000] loss: 0.910\n",
      "[Epoch 10, Batch 2000] loss: 0.830\n",
      "[Epoch 10, Batch 4000] loss: 0.814\n",
      "[Epoch 10, Batch 6000] loss: 0.840\n",
      "[Epoch 10, Batch 8000] loss: 0.866\n",
      "[Epoch 10, Batch 10000] loss: 0.869\n",
      "[Epoch 10, Batch 12000] loss: 0.897\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 61.62 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
