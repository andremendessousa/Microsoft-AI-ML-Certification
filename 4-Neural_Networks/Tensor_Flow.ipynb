{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6938a25d",
   "metadata": {},
   "source": [
    "Introduction\n",
    "In this activity, you will implement a neural network using TensorFlow. This activity provides hands-on experience with TensorFlow, a powerful framework for machine learning and deep learning.\n",
    "\n",
    "By the end of this activity, you will be able to:\n",
    "\n",
    "Build a simple feedforward neural network.\n",
    "\n",
    "Train the model on a dataset.\n",
    "\n",
    "Evaluate the model’s performance using TensorFlow.\n",
    "\n",
    "Step-by-step guide for implementing a neural network using TensorFlow\n",
    "Step 1: Set up the environment\n",
    "Before we start, ensure that TensorFlow is installed in your environment. You can install TensorFlow using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c00273",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 10:25:04.258413: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-24 10:25:04.537047: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-24 10:25:04.662907: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750760704.916612    9377 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750760705.010839    9377 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750760705.658395    9377 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750760705.658440    9377 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750760705.658444    9377 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750760705.658447    9377 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-24 10:25:05.688532: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd74cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a0fb322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the Fashion MNIST dataset\n",
    "(train_images, train_activityels), (test_images, test_activityels) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5222abfb",
   "metadata": {},
   "source": [
    "Explanation\n",
    "Normalizing the image data ensures that the neural network trains efficiently, as the pixel values range from 0 to 1 instead of from 0 to 255.\n",
    "\n",
    "Step 3: Define the neural network model\n",
    "Now you will define the architecture of the neural network using the TensorFlow Keras API. The network will consist of:\n",
    "\n",
    "An input layer that flattens the 28 × 28 image into a one-dimensional vector.\n",
    "\n",
    "A hidden layer with 128 neurons and the ReLU activation function.\n",
    "\n",
    "An output layer with 10 neurons (one for each fashion class) using softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9dc5001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ai-ml/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2025-06-24 10:37:33.175379: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),  # Input layer to flatten the 2D images\n",
    "    layers.Dense(128, activation='relu'),  # Hidden layer with 128 neurons\n",
    "    layers.Dense(10, activation='softmax') # Output layer with 10 classes\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68532560",
   "metadata": {},
   "source": [
    "Explanation\n",
    "Flatten layer: Converts the 28 × 28 matrix into a one-dimensional array of 784 features.\n",
    "\n",
    "Dense layers: A fully connected layer with 128 neurons and a ReLU activation function for the hidden layer, followed by an output layer with 10 neurons (one per class) that uses softmax to output probabilities.\n",
    "\n",
    "Step 4: Compile the model\n",
    "After defining the architecture, you need to compile the model. During compilation, you specify:\n",
    "\n",
    "The optimizer: For this activity, we will use Adam, a widely used optimizer that adjusts learning rates during training.\n",
    "\n",
    "The loss function: Since this is a classification task, we will use sparse categorical crossentropy.\n",
    "\n",
    "Metrics: We will track accuracy to monitor model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f0bbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de3f22d",
   "metadata": {},
   "source": [
    "Step 5: Train the model\n",
    "With the model compiled, you can now train it on the Fashion MNIST dataset. We will train the model for 10 epochs with a batch size of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3e631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 10:48:44.359131: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 188160000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7810 - loss: 0.6353\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8632 - loss: 0.3835\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.3381\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8854 - loss: 0.3131\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8923 - loss: 0.2927\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.2743\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9033 - loss: 0.2626\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2544\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.2495\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7db176b9b950>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_images, train_activityels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da48f77b",
   "metadata": {},
   "source": [
    "Explanation\n",
    "Epochs: This refers to the number of times the model will go through the entire training dataset. Ten epochs is a good starting point for this task.\n",
    "\n",
    "Batch size: This refers to the number of samples processed before the model’s weights are updated. A batch size of 32 is a common choice.\n",
    "\n",
    "Step 6: Evaluate the Model\n",
    "Once the model is trained, you can evaluate its performance on the test data. This will give you a sense of how well the model generalizes to new, unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a43116f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 45/313\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8956 - loss: 0.3389  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 10:55:27.075171: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 31360000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8880 - loss: 0.3450\n",
      "Test accuracy: 0.8842999935150146\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_images, test_activityels)\n",
    "\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8329af4f",
   "metadata": {},
   "source": [
    "Step 7: Experimentation (optional)\n",
    "After successfully implementing the basic neural network, you are encouraged to experiment with the model. Here are a few ideas:\n",
    "\n",
    "Add more hidden layers to make the network deeper.\n",
    "\n",
    "Change the number of neurons in the hidden layer.\n",
    "\n",
    "Try different activation functions, such as tanh or sigmoid, and observe their impact on the model’s performance.\n",
    "\n",
    "Adjust the optimizer: Test how using SGD instead of Adam affects training and accuracy.\n",
    "\n",
    "Example of adding another hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c1960",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),  # Additional hidden layer with 64 neurons\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
